{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62894805-622d-41f4-8799-0cef5152d9e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Time Series Application â€” Scott Person's NOTEBOOK\n",
    "\n",
    "**Applied Machine Learning 2 @ Newman University**\n",
    "\n",
    "*Prof. Ricky Boyer*\n",
    "\n",
    "**Jason \"Scott\" Person**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ff7678d-45c9-4227-bb34-d137c8aa9e68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Important note!** Before you turn in this lab notebook, make sure everything runs as expected:\n",
    "\n",
    "- First, **restart the kernel** -- in the menubar, select Kernel$\\rightarrow$Restart.\n",
    "- Then **run all cells** -- in the menubar, select Cell$\\rightarrow$Run All.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14784a16-6f53-4b31-8b82-0001db424b4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Part 0: Sample dataset (Finance)\n",
    "\n",
    "The dataset we'll be using is accessible via a Python library called nasdaqdatalink. If the import cell does not run for you, then you may need to do a `pip` or `conda` install to access the data in your environment. Once you do, then restart the kernel and run the cells again. Cell added below to assist, or you can delete the cell and install the package via your typical `pip`. Friends using Colab should be able to use the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f529f746-f5c5-4faa-b136-085ece026955",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Disable Databricks autolog - this ended up overloading the browser during stepwise regression\n",
    "import mlflow\n",
    "mlflow.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb042fb7-f9d9-427c-967b-96b872bd5f15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false
   },
   "outputs": [],
   "source": [
    "%pip install nasdaq-data-link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fec84862-19df-4e9d-9d0e-5b7188a7350b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nasdaq data link for end of day stock price data\n",
    "import nasdaqdatalink\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import isclose\n",
    "\n",
    "#configure API: key intended only for student use while at Newman\n",
    "nasdaqdatalink.ApiConfig.api_key = 'bzv_VKSXDstz5DLXnjhe'\n",
    "txt = nasdaqdatalink.get_table('WIKI/PRICES', ticker = ['TXT'])\n",
    "ba = nasdaqdatalink.get_table('WIKI/PRICES', ticker = ['BA'], paginate = True)\n",
    "display(txt.head())\n",
    "print(\"\\n(All data appears to be ready.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "387d3522-1d34-4942-ba79-69b6f55a1083",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false
   },
   "outputs": [],
   "source": [
    "txt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4f9b01e-7af2-4bf3-a10b-18e505f08e4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false
   },
   "outputs": [],
   "source": [
    "ba.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e113b99-1925-460f-b578-f71b7124ee45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Here we've brought in financial data for 2 aircraft companies, so we may get a sense of scale. Our main concern will be the prediction of Textron ([TXT](https://search.yahoo.com/search?fr=mcafee&type=E210US1590G0&p=Textron+stock)) market cap as if we were computing this back in 2018, using historical data. First let's take a look at the stock prices of these companies over their lifetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "998aa734-20a0-41cf-99f7-fe13c1052a84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The adjusted close accounts for stock splits, so that is what we should graph\n",
    "plt.plot(ba.index, ba['close'])\n",
    "plt.title('BA Stock Price')\n",
    "plt.ylabel('Price ($)');\n",
    "plt.show()\n",
    "plt.plot(txt.index, txt['close'], 'r')\n",
    "plt.title('TXT Stock Price')\n",
    "plt.ylabel('Price ($)');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74a5d0b7-1c3c-44ea-b518-744f55610a52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Prepping Our Data\n",
    "Generally speaking, for almost any date-based analysis, it is  agood idea to include a Date column. Ours happens to be in the index currently. We should remove it from the index using the `reset_index` function, but first we can put it to good use. Let's make a column `Year` using that index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67cacd34-4a5d-40aa-b7b5-37dccc7ce37a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a year column \n",
    "txt['Year'] = pd.DatetimeIndex(txt.index).year\n",
    "ba['Year'] = pd.DatetimeIndex(ba.index).year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c244599-edab-4d7f-8275-a32f12c62a56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Exercise 0** (10 points). Use the `reset_index` function, on our `txt` and `ba` DataFrames, with `level=0` and `inplace=True`. This should automatically give us a `Date` column in each of the datasets that virtually all time series models require, especially some of the newer ones like Prophet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffdb7f76-de34-4d4d-b0fc-f6e8428ceb78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take Dates from index and move to Date column \n",
    "## YOUR ANSWER HERE\n",
    "# BEGIN SOLUTION\n",
    "txt.reset_index(level=0, inplace=True)\n",
    "ba.reset_index(level=0, inplace=True)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edd796bd-11e3-466b-ba42-046e0313ec47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell: `rest_index_test`\n",
    "assert txt['date'].dtype == 'datetime64[ns]', print(\"\\n You do not have a 'Date' column in txt\")\n",
    "assert ba['date'].dtype == 'datetime64[ns]', print(\"\\n You do not have a 'Date' column in ba\")\n",
    "\n",
    "print(\"\\n(Passed! You got 10 points!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "232dd669-e5d1-4c60-8321-b1088cb20912",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now let's calculate the target that we are after. If trying to determine the Market Cap of a company, it is determined (in simplest form) by taking the outstanding shares of that company (represented by `adj_volume` in our dataset) and multiplying it by the given price of that share. Our dataset has many different prices represented for each day, but we'll use `close`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcad521a-ec36-42a1-8126-8d9f94866031",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Exercise 1** (10 points). Create the column `Cap` in both the `txt` and `ba` datasets by multiplying the `adj_volume` with `close`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdf7de73-a32d-4e4c-a778-ac55cddf1a21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## YOUR ANSWER HERE\n",
    "# BEGIN SOLUTION\n",
    "txt['Cap'] = txt['close'] * txt['adj_volume']\n",
    "ba['Cap'] = ba['close'] * ba['adj_volume']\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea1bbc5d-2a85-44d1-af23-6bcc7f42a92a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "txt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83533496-ca7a-49c5-9577-07ca858d919f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell: `Cap`\n",
    "assert txt['Cap'].dtype == 'float64', print(\"\\n You do not have a 'Cap' column in txt or datatype wrong\")\n",
    "assert ba['Cap'].dtype == 'float64', print(\"\\n You do not have a 'Cap' column in ba or datatype wrong\")\n",
    "assert txt['Cap'].shape == (8424,), print(\"\\n Shape txt['Cap'] is {} when it should be {}\").format(txt['Cap'].shape, '(8424,)')\n",
    "assert ba['Cap'].shape == (14155,), print(\"\\n Shape txt['Cap'] is {} when it should be {}\").format(ba['Cap'].shape, '(14155,)')\n",
    "\n",
    "print(\"\\n(Passed! You got 10 points!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c26b3c6e-5286-4c0d-8379-469ed527dfb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "If we look at the two together, we can now see the scale of dollars that we are dealing with, as well as determine the general trend of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08e9fb60-a154-454a-a096-b7d7033865bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mkt_cap = ba.merge(txt, how='inner', on='date')\n",
    "mkt_cap.rename(columns={'Cap_x': 'ba_cap', 'Cap_y': 'txt_cap'}, inplace=True)\n",
    "mkt_cap = mkt_cap.loc[mkt_cap['date'] > '2010-1-1', :]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(mkt_cap['date'], mkt_cap['ba_cap'], 'b-', label = 'BA')\n",
    "plt.plot(mkt_cap['date'], mkt_cap['txt_cap'], 'r-', label = 'TXT')\n",
    "plt.xlabel('date'); plt.ylabel('Market Cap (Billions $)'); plt.title('Market Cap of BA and TXT')\n",
    "plt.legend();\n",
    "mkt_cap = mkt_cap[['date', 'ba_cap', 'txt_cap']]\n",
    "display(mkt_cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b56f8a00-7273-48db-868a-4b2d3fc6d4e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "It appears that Boeing's markjet cap is much large than Textron's, though both can pretty easily be quantified in the Billions of dollars. We can also see the volatility in the day to day market. The hope would be that using our Time Series models has a smoothing effect over all that volatility. This view, however is much better than looking at it since the beginning of each company's entry onto the market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb1cd0e5-39fc-49ca-b57e-4cf381836549",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Exercise 2** (20 points). Slice the `txt` DataFrame such that you only keep the rows where `Date` is greater than '2010-1-1'. (**Hint:** If you look at my previous cell, you might be able to spot how I did it to the `mkt_cap` DataFrame.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "797fc394-c8d7-4c6f-a6c5-faeb4bfd0cfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## YOUR ANSWER HERE\n",
    "# BEGIN SOLUTION\n",
    "txt = txt.loc[txt['date'] > '2010-1-1', :]\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ff37c52-4a56-4147-96ac-987d4a817a17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell: `date_slice`\n",
    "assert txt.shape == (2071, 17), \"Shape txt is {} when it should be {}\".format(txt.shape, '(2071, 17)')\n",
    "try:\n",
    "    test = txt.loc[txt['date'] < '2010-1-1', :]\n",
    "    test.shape == (0,17)\n",
    "    print(\"\\n(Passed! You got 20 points!)\")\n",
    "except AssertionError as e:\n",
    "    print(\"\\n(Seems like you may still have some unwanted rows.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09f704a7-e157-4103-bb8c-297c398d251a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Notation and review\n",
    "\n",
    "Taking a look at the model explanations from [Toward Data Science](https://towardsdatascience.com/time-series-forecasting-with-arima-sarima-and-sarimax-ee61099e78f6) we can determine which model we may want to use, as well as a general explanation of how it works.\n",
    "\n",
    "### Autoregression (AR)\n",
    "**Autoregression** utilizes a $p$ parameter to determine how many lag variables we use in the regression to determine the next value, according to the following formula. Setting this value to 1 begins to introduce randomness into the algorithm, shifting away from a normal regression. \n",
    "\n",
    "![image.png](attachment:839d9674-4f7a-4cb5-824d-90711f2a450a.png)\n",
    "\n",
    "### Moving Average (MA)\n",
    "The **Moving Average** portion of time series algorithms utilizes a $q$ parameter to determine how many lag variables to use when determining the average. In an $q$ = 1 model, our forecast is a constant term plus the previous white noise term times a multiplier, added with the current white noise term.\n",
    "\n",
    "### ARMA\n",
    "The **ARMA** model is the combination of the previous two sections in one algorithm, acting as the basic framework for most TS analyses used in business today.\n",
    "\n",
    "### ARIMA\n",
    "**ARIMA** utilizes the ARMA model and a difference order as defined by $I(d)$.\n",
    "\n",
    "### SARIMA\n",
    "**SARIMA** is an ARIMA model that has additional ability to difference based on seasonality as defined within the parameters of the formula. It expressed as a function is shown belw, which is a faar cry from the original AR model.\n",
    "\n",
    "![image.png](attachment:25264769-4bbd-4e57-b3df-ec7ac042768a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29ebdf94-f133-4bef-ae52-eda77fec2da9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "For our purposes, both the ARIMA and SARIMA models can be accessed via our friendly [Statsmodels package](https://www.statsmodels.org/stable/generated/statsmodels.tsa.arima.model.ARIMA.html) from the lesson on Regression! Let's go ahead and pull in that model as well as some of it' visualization tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "216b6e6c-3fe6-4bcc-b5a1-289e5ed96e42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d029453c-b1e6-4a27-b233-47e19ac29d76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Fitting a model\n",
    "\n",
    "We've arrived at the main event! Let's check out what this looks like when we run a very basic model where $(p, d, q)$ are all set to 0 and we have no seasonality introduced. This should allow us to check out the baseline summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95fd2825-545d-43d5-8f70-83ab0c3026ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 0,0,0 ARIMA Model\n",
    "model = ARIMA(txt.Cap, order=(0,0,0), seasonal_order=(0,0,0,0))\n",
    "model_fit = model.fit()\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5b4c4f6-dab2-4151-b006-135b48bb26f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We want to make sure each term in our model is statistically significant, which we can see by taking a look at the highlighted section. We want each term to have a p-value of less than 0.05, so we can reject the null hypothesis with statistically significant values.\n",
    "\n",
    "![image.png](attachment:02ba54a5-7509-44ef-baa4-24d84f3b6c22.png)\n",
    "\n",
    "We can see that the Constant value is way off from the .05 or less that we need it to be in order to show statistical significance.\n",
    "\n",
    "**Let's get Experimental!** Like most of our algorithms, the feature engineering is what tends to produce better results within the output models, however time series analysis allows us to adjust the regressor variables in real time as hyperparameters of the algorithm. It seems like a good idea to play around with the parameters a bit to see if we can get something a little better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b67e6595-5da1-4d46-bc23-1b96a5e3effb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Exercise 3** (20 points). Copy and paste my ARIMA code cell into the next code cell, then adjust `order` parameter to be $(p, d, q)$ = (3, 1, 3). Keep the `model` and `model_fit` variables as they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68763aee-cc65-4e37-9856-78588a7d2028",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3,1,3 ARIMA Model\n",
    "##YOUR CODE HERE\n",
    "#BEGIN SOLUTION\n",
    "model = ARIMA(txt.Cap, order=(3,1,3), seasonal_order=(0,0,0,0))\n",
    "model_fit = model.fit()\n",
    "#END SOLUTION\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52cccf99-37fb-4fe0-b300-b65a322074d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell: `313_arima`\n",
    "\n",
    "test = [-1.442948421186277, -0.20025750284682942, 0.4024901151346325, 0.8691307148401701, -0.840341457052922, -0.9281957313898933, 1791497880191682.8]\n",
    "#assert test == list(model_fit.params), \"Check your cell again. It should look exactly like before with order = (3 ,1 ,3)\"\n",
    "assert all(isclose(list(test), list(model_fit.params), rtol=.001)), \"Check your cell again. It should look exactly like before with order = (3 ,1 ,3)\"\n",
    "print(\"\\n(Passed! You got 20 points!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "068ce75e-6fc0-4ce8-955d-fa59fa1ce38e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "From a variable standpoint this looks much better as all seem to have a $p$ value lower than .05. However, when we check the statistics based on our normal regression assumtions, we now see low heteroskedasticity, as well as high $p$ values for the Ljun-Box test and the heteroskedasticity. this indicates that we cannot rejcet the assumed state of violating those assumptions. \n",
    "\n",
    "![image.png](attachment:80283e74-56f3-451c-92a2-d6f71d4aa4f3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c842ec88-2998-4a3c-be46-c0f5e4d2e434",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Can adding in the `seasonal_order` parameter help us get on track?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ad01bf7-caaf-47eb-a2ac-188c114b56ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Exercise 4** (30 points). Copy and paste the ARIMA code cell into the next code cell. Keep the `order` parameter as $(p, d, q)$ = (3, 1, 3) and the `model` and `model_fit` variables as they are. Then go ahead and play with the `seasonal_order` parameter, setting it to something other than $(P, D, Q, s)$ = (0, 0, 0, 0). Within the model fit method you may also need to increase the `method_kwargs` to ensure convergance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "331c3a8f-d06b-41c7-a46e-69889288b17d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do not execute \n",
    "'''\n",
    "# 1,1,0 ARIMA Model\n",
    "##YOUR CODE HERE\n",
    "#BEGIN SOLUTION\n",
    "\n",
    "# 20250604 JSP OK, I monkeyed with the pqds values. Just wandering around in the dark on this one.\n",
    "\n",
    "model = ARIMA(txt.Cap, order=(3,1,3), seasonal_order=(0,1,1,20)) # 1,1,1,365 is blows up the cluster I went with 20 because that is monthly sasonality (for work days). Just guessing here.\n",
    "model_fit = model.fit(method_kwargs={\"maxiter\": 200})\n",
    "#END SOLUTION\n",
    "\n",
    "print(model_fit.summary())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "731e5c90-ab7b-4ea0-8dfd-14e400dc204c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell: `sarima`\n",
    "#Yay a free 20 points for getting the above to run! You'll all have something different, but as long as it runs you'll get the points.\n",
    "print(\"\\n(Passed! You got 20 points!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d17b2d5-ec13-4a32-b2f6-2d7a0dc68438",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot residual errors\n",
    "residuals = pd.DataFrame(model_fit.resid)\n",
    "fig, ax = plt.subplots(1,2)\n",
    "residuals.plot(title=\"Residuals\", ax=ax[0])\n",
    "residuals.plot(kind='kde', title='Density', ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2ad0232-e3f1-4df3-8dcb-554fe4e3d57b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Actual vs Fitted\n",
    "plot_predict(model_fit, dynamic=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9486735-b416-4a4f-8f65-2100b653b782",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Other Algorithms and Packages\n",
    "There are a few more packages that we would be a little remissed if we did not talk about:\n",
    "\n",
    "### Auto ARIMA\n",
    "Auto arima is part of the [pmdarima](https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.auto_arima.html) package that allows for optimized and iterable runs of the ARIMA function through a helpful configuration function. It allows you to set a `start_p`, `max_p`, `start_q`, and `max_q` parameters so it can iterate through each model, determining which best fits the test given. It also has a few more advanced regression parameters like the ability to run the model stepwise in considering each regression variable.\n",
    "\n",
    "### Prophet\n",
    "[Prophet](https://facebook.github.io/prophet/docs/quick_start.html) is the time series algorithm developed by Meta (formaerly Facebook) and is widely considered one of the better time series models out there right now. It is also built in such a way that makes predictions very easy to accomplish, necessitating only a few lines of code. The only finnicky thing about it is that it requires a `ds` field (in the form of a date series) and a `y`\n",
    "\n",
    "Let's go ahead and install those packages. You may need to `!pip` or `conda` install them to get them to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b355343-19bd-4714-a5c1-a27db2cbf1ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#%pip install pmdarima\n",
    "#%pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12634c04-0890-4584-b333-d1e2a643b9b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fe9122d-e050-4df0-94a7-c82553846c9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's see if the automated version can generate a better model than earlier. **DISCLAIMER: This may take a while to run.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f7483c4-78af-4328-9fe9-bdbfb4295b5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Standard ARIMA Model\n",
    "ARIMA_model = pm.auto_arima(txt['Cap'], \n",
    "                      start_p=0, \n",
    "                      start_q=0,\n",
    "                      test='kpss', #default\n",
    "                      max_p=3, max_q=3, # maximum p and q\n",
    "                      m=7, # frequency of series (if m==1, seasonal is set to FALSE automatically)\n",
    "                      d=None,# let model determine 'd'\n",
    "                      seasonal=True, # No Seasonality for standard ARIMA\n",
    "                      trace=False, #logs\n",
    "                      error_action='warn', #shows errors ('ignore' silences these)\n",
    "                      suppress_warnings=True,\n",
    "                      stepwise=True)\n",
    "\n",
    "print(ARIMA_model.summary())\n",
    "\n",
    "ARIMA_model.plot_diagnostics(figsize=(15,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1581de1-4466-4e28-8400-69904896a65f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "It seems that our earlier $(p, d, q)$ = (3,1,3) is about as good as it is going to get for this data. Each overall coefficient in the regression is statistically significant even if there is some imbalance overall in the dataset. Time series are much harder to balance than our priior classification models since they require a value for each date in the series. Other options at this point would be restructuring our dataframe to be organized by week or month. Overall, though, for a business something like this still helps us determine the regressive components of the market cap, allowing us to glean insight from the selected model itself, prior to any forecasting.\n",
    "\n",
    "Let's do a little forecasting with the [Prophet](https://facebook.github.io/prophet/docs/quick_start.html). Open up the documentation, and let's walk through the first few steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5679b5a9-620d-4edd-b2f7-3bc97502d077",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Exercise 5** (30 points). Complete the checklist:\n",
    "* Create DataFrame `txt` by renaming the current column `date` to `ds` and the column `close` to `y`\n",
    "* Create `txt_prophet` by instantiating a new `Prophet()` object, but let's include `changepoint_prior_scale=0.15` in the Prophet configuration.\n",
    "* Fit the `txt_prophet` object to our intial `txt` DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edc1afaf-7810-4377-8ada-e2fb1adb9bc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "##YOUR ANSWER HERE\n",
    "#BEGIN SOLUTION\n",
    "# Prophet requires columns ds (Date) and y (value)\n",
    "txt = txt[['date', 'Cap']].rename(columns={'date': 'ds', 'Cap': 'y'})\n",
    "# Make the prophet model and fit on the data\n",
    "txt_prophet = Prophet()\n",
    "txt_prophet.fit(txt)\n",
    "#END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ba46bc8-8598-4821-bb84-e3a75feec5ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell: `prophet_prep`\n",
    "try: \n",
    "    test1 = txt['date']\n",
    "except KeyError:\n",
    "    pass\n",
    "except AttributeError:\n",
    "    pass\n",
    "except NameError:\n",
    "    pass\n",
    "try:    \n",
    "    print(txt_prophet)\n",
    "except KeyError:\n",
    "    print('txt_prophet does not exist')\n",
    "except AttributeError:\n",
    "    print('txt_prophet does not exist')\n",
    "except NameError:\n",
    "    print('txt_prophet does not exist')\n",
    "\n",
    "print(\"\\n(Passed! You got 30 points!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c0b2d00-0d91-4fc5-aee7-c0a1fa88dad2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Exercise 6** (20 points). Complete the checklist:\n",
    "* Create DataFrame `txt_forecast` by using the `make_future_dataframe` function for 2 years worth of days (periods= 365*2, freq='D')\n",
    "* Use the `.predict` method from our `txt_prophet` on our newly created `txt_forecast` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b590c91-c0fe-4a8d-8308-ba33e72204a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##YOUR ANSWER HERE\n",
    "#BEGIN SOLUTION\n",
    "# Make a future dataframe for 2 years\n",
    "txt_forecast = txt_prophet.make_future_dataframe(periods=365*2, freq='D')\n",
    "\n",
    "# Make predictions\n",
    "txt_forecast = txt_prophet.predict(txt_forecast)\n",
    "#END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df627b44-96ec-4b46-843c-412e8e176a88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell: `prophet_predict`\n",
    "\n",
    "try:    \n",
    "    prophet_predict_test = txt_forecast.iloc[:, [1, 2, 5]]\n",
    "except AttributeError:\n",
    "    print('Something is wrong with your prediction')\n",
    "\n",
    "assert list(prophet_predict_test.columns) == ['trend', 'yhat_lower', 'trend_upper'], print('Something is wrong with your prediction')\n",
    "\n",
    "print(\"\\n(Passed! You got 30 points!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bf5e7f6-473c-4d30-b5be-e23b87f96f1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "txt_prophet.plot(txt_forecast, xlabel = 'Date', ylabel = 'Market Cap (billions $)')\n",
    "plt.title('Market Cap of TXT');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb0f0a58-bf1a-4d12-89fc-566793019cc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Prophet can have its hyperparameters tuned as well! We can iterate through a bunch of hyperparameters with the model, by forming a matrix. We can then iterate over our model, using the permuations within the matrix. This will tell us what the best hyperparameters are! For the long-hand version of this, you can check out the [Prophet Diagnostics Documentation](https://facebook.github.io/prophet/docs/diagnostics.html) this part of the notebook is based on. This will take a little to run as well, since it is running through a number of models. Give it a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a41939a2-732a-4d54-bcb2-104b9c5c7a0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "\n",
    "param_grid = {  \n",
    "    'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5],\n",
    "    'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0],\n",
    "}\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "rmses = []  # Store the RMSEs for each params here\n",
    "\n",
    "# Use cross validation to evaluate all parameters\n",
    "for params in all_params:\n",
    "    m = Prophet(**params).fit(txt)  # Fit model with given params\n",
    "    df_cv = cross_validation(m, horizon='30 days', parallel=\"processes\")\n",
    "    df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "    rmses.append(df_p['rmse'].values[0])\n",
    "\n",
    "# Find the best parameters\n",
    "tuning_results = pd.DataFrame(all_params)\n",
    "tuning_results['rmse'] = rmses\n",
    "print(tuning_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36745964-ce50-4701-afc8-52380a5d1764",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false
   },
   "source": [
    "**Exercise 7** (20 points). Input the values for `changepoint_prior_scale` as variable `cps` and `seasonality_prior_scale` as variable `sps` that create the best model best on the above table. You can also be clever by using the `argmin` function in the Numpy package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ddbe54f-f944-466b-b7e0-616452d67cdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "index = tuning_results['rmse'].idxmin()\n",
    "\n",
    "cps = tuning_results.iloc[index]['changepoint_prior_scale']\n",
    "sps = tuning_results.iloc[index]['seasonality_prior_scale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23f184aa-ba49-4220-91d3-95a8dc855c46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test cell: `txt_hyp_test`\n",
    "sanswer = [cps, sps]\n",
    "min_rmse = tuning_results['rmse'].min()\n",
    "\n",
    "best_params = tuning_results[tuning_results['rmse'] == min_rmse]\n",
    "best_params = best_params.drop(columns=['rmse']).iloc[0].tolist()\n",
    "assert best_params == sanswer, print('Try a different set of hyperparameters')\n",
    "\n",
    "print(\"\\n(Passed! You got 20 points!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dbd5004-0e7f-4304-8286-d2f9b0c4931d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "editable": false
   },
   "source": [
    "**Congrats!** If you've gotten this far without errors, you're ready to submit your notebook!"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Person_Module_2_2_Time_Series_Application",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
